{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "insta_model",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VChCyFgXzh1"
      },
      "source": [
        "import os\n",
        "import json\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import math\n",
        "import tensorflow as tf\n",
        "import random\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from random import randrange\n",
        "\n",
        "IMG_WIDTH = 224\n",
        "IMG_HEIGHT = 224\n",
        "NORMALIZE = True\n",
        "TEST_SIZE = 500\n",
        "READ_SIZE = 10000\n",
        "#Das garantiert nicht eine Test size, sondern ist nur ein maximum für die test size, solange nicht alle bilder entzippt wurden\n",
        "\n",
        "# number of learnings should be until the loss converges otherwise we overfit\n",
        "EPOCHS = 50\n",
        "TOTAL_EPOCHS = EPOCHS + 300\n",
        "NUM_CATEGORIES = 3\n",
        "# drop out nodes at random to make the network more robust\n",
        "DROPOUT = 0.2\n",
        "HIDDENLAYERS_SIZE = 64\n",
        "STEPS_PER_EPOCH = 1\n",
        "IMG_SIZE = (IMG_WIDTH, IMG_HEIGHT)\n",
        "IMG_SHAPE = (IMG_HEIGHT,IMG_WIDTH,3)\n",
        "INPUT_SHAPE = (IMG_WIDTH, IMG_HEIGHT, 3)\n",
        "\n",
        "INSTA_DATA = '/storage/insta_data/insta_data/'\n",
        "IMAGES_DIR = INSTA_DATA+'Post images (JPG files)/images/'\n",
        "INFO_DIR = INSTA_DATA+'Post metadata (JSON files)/inof/'\n",
        "org_stdout = sys.stdout\n",
        "image_mapping = {}\n",
        "info_mapping = {}\n",
        "print(\"Test\")\n",
        "print(sys.stdout)\n",
        "print(org_stdout)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTHjdAmxX0cd"
      },
      "source": [
        " with open(INSTA_DATA+\"influencers.txt\",'r') as f:\n",
        "        f.readline()\n",
        "        f.readline()\n",
        "        line = f.readline().split(\"\\t\")\n",
        "        while len(line) == 5:\n",
        "            info_mapping[line[0]] = {\n",
        "                'category':line[1],\n",
        "                'followers':line[2],\n",
        "                \"following\":line[3],\n",
        "                'posts':line[4].rstrip()\n",
        "            }\n",
        "            line = f.readline().split(\"\\t\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pBKtSLBX2Kj"
      },
      "source": [
        "\n",
        "\n",
        "def image_train(skip = 0,till=-1,Fast=True,batch_size=32):\n",
        "    if Fast:\n",
        "        out_images = []\n",
        "        out_labels = []\n",
        "        #hier werden jeweils Bild-Metadaten paare gespeichert, damit diese dann eingelesen werden können.\n",
        "        with open(\"pairs_w_dupes.txt\",\"r\") as pi:\n",
        "            for i in range(skip):\n",
        "                next(pi)\n",
        "            lines_read = skip+1\n",
        "            l = pi.readline()[63:].rstrip()\n",
        "            while not l == '' and (lines_read < skip+till or till < 0):\n",
        "                if len(out_images) == batch_size:\n",
        "                    yield np.array([i for i in out_images]), np.array([i for i in out_labels])\n",
        "                    out_labels = []\n",
        "                    out_images = []\n",
        "                info_file = INFO_DIR+l\n",
        "                image_file = IMAGES_DIR+l.replace(\".info\",\".jpg\")\n",
        "                influencer = l[:l.rfind(\"-\")]\n",
        "                if (os.path.exists(image_file)) and influencer in info_mapping:\n",
        "                    followers = int(info_mapping[influencer]['followers'])\n",
        "                    following = int(info_mapping[influencer]['following'])\n",
        "                    info = {}\n",
        "                    with open(info_file,'r') as info_file_object:\n",
        "                        info = json.loads(info_file_object.read())\n",
        "                        like = int(info[\"edge_media_preview_like\"][\"count\"])\n",
        "                    image = cv2.imread(image_file)\n",
        "                    resized = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT),interpolation=cv2.INTER_AREA)\n",
        "                    # make the input better for the neural network\n",
        "                    if(NORMALIZE):\n",
        "                        resized = resized / 255.0\n",
        "                    #print('shape '+resized.shape())\n",
        "                    out_images.append(resized)\n",
        "                    out_labels.append(like)\n",
        "                else:\n",
        "                    print('CRITICAL ERROR')\n",
        "                    print(image_file)\n",
        "                l = pi.readline()[63:].rstrip()\n",
        "                lines_read += 1\n",
        "        max_like = max(out_labels)\n",
        "        var = np.var(out_labels)\n",
        "        mean = np.mean(out_labels)\n",
        "        sqr_var = math.sqrt(var)\n",
        "        yield np.array([i for i in out_images]), np.array([i/max_like for i in out_labels])\n",
        "    else:\n",
        "      #hier kann nach neuen Bild-Metadaten Paaren gesucht werden, die dann auch gespeichert werden (können)\n",
        "        with open(INSTA_DATA+\"JSON-Image_files_mapping.txt\",'r') as f:\n",
        "            print(skip)\n",
        "            print(till)\n",
        "            f.readline()\n",
        "            for _ in range(skip):\n",
        "                next(f)\n",
        "            line = f.readline().split(\"\\t\")\n",
        "            line[2].rstrip()\n",
        "            '''with open(\"pairs.txt\",\"w+\") as p:\n",
        "                p.write('')\n",
        "                print('cleared pairs')'''\n",
        "            readline = 2+skip\n",
        "            one_image_posts = 0\n",
        "            info_file = \"\"\n",
        "            image_str = \"\"\n",
        "            image_file = \"\"\n",
        "            infos = 0\n",
        "            images = 0\n",
        "            out = []\n",
        "            out_images = []\n",
        "            out_labels = []\n",
        "            while len(line) == 3 and (readline < till or till<0):\n",
        "                if len(out_images) == batch_size:\n",
        "                    yield np.array([i for i in out_images]), np.array([i for i in out_labels])\n",
        "                    out_labels = []\n",
        "                    out_images = []\n",
        "                line[2] = line[2].rstrip()\n",
        "                strs = line[2][2:-2].split(',')\n",
        "                if len(strs) == 1:\n",
        "                    one_image_posts += 1\n",
        "                    info_file = INFO_DIR+line[0]+'-'+line[1][:-5]+'.info'\n",
        "                    image_str = strs[0].lstrip().replace(\"'\",\"\")\n",
        "                    image_file = IMAGES_DIR+line[0]+'-'+image_str\n",
        "                    if os.path.exists(info_file):\n",
        "                        infos+=1\n",
        "                    if(os.path.exists(image_file)):\n",
        "                        images+=1\n",
        "                    if os.path.exists(info_file) and os.path.exists(image_file):\n",
        "                        print('YAY')\n",
        "                        followers = int(info_mapping[line[0]]['followers'])\n",
        "                        following = int(info_mapping[line[0]]['following'])\n",
        "                        info = {}\n",
        "                        with open(info_file,'r') as info_file_object:\n",
        "                            info = json.loads(info_file_object.read())\n",
        "                            print(info.keys())\n",
        "                            like = int(info[\"edge_media_preview_like\"][\"count\"])\n",
        "                            #print(info['likes']\n",
        "                        print(image_file)\n",
        "                        image = cv2.imread(image_file)\n",
        "                        resized = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT),interpolation=cv2.INTER_AREA)\n",
        "                        # make the input better for the neural network\n",
        "                        if(NORMALIZE):\n",
        "                            resized = resized / 255.0\n",
        "                        print(str(infos) +' '+str(images))\n",
        "                        with open('/storage/pairs.txt','a+') as pa:\n",
        "                            pa.write(info_file+'\\n')\n",
        "                        #print('shape '+resized.shape())\n",
        "                        out_images.append(resized)\n",
        "                        out_labels.append((like-following)/(followers-following))\n",
        "                            \n",
        "                line = f.readline().split(\"\\t\")\n",
        "                readline += 1\n",
        "                if readline%10000 == 0:\n",
        "                    line[2] = line[2].rstrip()\n",
        "                    strs = line[2][2:-2].split(',')\n",
        "                    print(line)\n",
        "                    print(readline)\n",
        "                    print(strs)\n",
        "                    print(line[2])\n",
        "                    print(one_image_posts)\n",
        "                    print(str(os.path.exists(info_file))+info_file)\n",
        "                    print(str(os.path.exists(image_file))+image_file)\n",
        "                    print(str(images))\n",
        "                    print(str(infos))\n",
        "#add tensorflow methods and shape of dataset (see x_train)\n",
        "\n",
        "\n",
        "x_train,y_train = next(image_train(skip=TEST_SIZE,till=TEST_SIZE+READ_SIZE,batch_size=READ_SIZE))\n",
        "x_test,y_test = next(image_train(till=TEST_SIZE,batch_size=TEST_SIZE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iix66wO2X3ho"
      },
      "source": [
        "\n",
        "\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                                  include_top=False,\n",
        "                                               weights='imagenet')\n",
        "LEARNING_RATE = 0.001\n",
        "# batchsize = x -> could define one // woundn't use it except if it takes to long\n",
        "# it is the amount of images in the data set which \n",
        "# is getting looked at before an adjustment\n",
        "\n",
        "\n",
        "def main():\n",
        "    txt = sys.stdout\n",
        "    sys.stdout = org_stdout\n",
        "    sys.stdout = open('file5.txt', 'w+')\n",
        "    print(txt)\n",
        "    print(len(x_train))\n",
        "    print(len(x_test))\n",
        "    model = get_model()\n",
        "    if True: \n",
        "      model = tf.keras.models.load_model('/storage/Deep_CNN')\n",
        "\n",
        "    #grid search\n",
        "    \"\"\"\n",
        "    model = KerasClassifier(build_fn = lambda:get_model())\n",
        "    \n",
        "    batch_size = [10, 50, 100]\n",
        "    epochs = [5, 10 , 20,  50, 100]\n",
        "    dropout_rate = [0.1, 0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
        "    pool_type =  ['max', 'average']\n",
        "    param_grid = dict(batch_size = batch_size, epochs = epochs)\n",
        "    grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, cv=3,\n",
        "                        verbose = 2)\n",
        "    grid_result = grid.fit(x_train, y_train)\n",
        "    # summarize results\n",
        "    print(\"Best: %f using %s\" % (grid_result.best_score_,\n",
        "                                 grid_result.best_params_))\n",
        "    means = grid_result.cv_results_['mean_test_score']\n",
        "    stds = grid_result.cv_results_['std_test_score']\n",
        "    params = grid_result.cv_results_['params']\n",
        "    for mean, stdev, param in zip(means, stds, params):\n",
        "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
        "    \"\"\"\n",
        "    print(TEST_SIZE)\n",
        "    # Fit model on training data\n",
        "    History = model.fit(x=x_train,y=y_train, verbose=2,epochs=EPOCHS)\n",
        "\n",
        "     # Evaluate neural network performance\n",
        "    model.evaluate(x=x_test,y=y_test, verbose=2)\n",
        "\n",
        "\n",
        "    # prepare the base model\n",
        "    base_model.trainable = True\n",
        "\n",
        "    # Let's take a look to see how many layers are in the base model\n",
        "    print(\"Number of layers in the base model: \", len(base_model.layers))\n",
        "\n",
        "    # Fine-tune from this layer onwards\n",
        "    fine_tune_at = 100\n",
        "\n",
        "    # Freeze all the layers before the `fine_tune_at` layer\n",
        "    for layer in base_model.layers[:fine_tune_at]:\n",
        "      layer.trainable =  False\n",
        "    model.summary()\n",
        "\n",
        "    for layer in base_model.layers[fine_tune_at:]:\n",
        "      if layer.name[-2:] == \"BN\" or layer.name[-2:] == \"bn\":\n",
        "        layer.trainable = False\n",
        "    model.summary()\n",
        "    \n",
        "    decayrate = 1\n",
        "    \n",
        "    #finds the last learning rate of the pretrained model\n",
        "    base_learning_rate = LEARNING_RATE / (1 + decayrate * STEPS_PER_EPOCH /\n",
        "                                          STEPS_PER_EPOCH*1000)\n",
        "\n",
        "    #compile the model for finetuning\n",
        "    model.compile(loss=\"mean_absolute_percentage_error\",\n",
        "              optimizer = tf.keras.optimizers.RMSprop(\n",
        "                  learning_rate=base_learning_rate),\n",
        "              metrics=[\"mean_absolute_percentage_error\"]\n",
        "              )\n",
        "\n",
        "    #train the finetuned model with a smaler learningrate\n",
        "    history_fine =  model.fit(x=x_train, y=y_train,\n",
        "                         epochs=TOTAL_EPOCHS,\n",
        "                         initial_epoch=History.epoch[-1],verbose=2)\n",
        "\n",
        "    # Evaluate neural network performance\n",
        "\n",
        "    sys.stdout = open('file4.txt', 'w+')\n",
        "    model.evaluate(x=x_test,y=y_test, verbose=2)\n",
        "    model.summary()\n",
        "    \n",
        "    filename = (\"/storage/Deep_CNN\")\n",
        "    model.save(filename)\n",
        "\n",
        "    # Save model to file\n",
        "    #if len(sys.argv) == 3:\n",
        "    #    filename = sys.argv[2]\n",
        "    #    model.save(filename)\n",
        "    #    #print(f\"Model saved to {filename}.\")\n",
        "\n",
        "def get_model():\n",
        "    \"\"\"\n",
        "    Returns a compiled convolutional neural network model. Assume that the\n",
        "    `input_shape` of the first layer is `(IMG_WIDTH, IMG_HEIGHT, 3)`.\n",
        "    The output layer should have `NUM_CATEGORIES` units, one for each category.\n",
        "    \"\"\"\n",
        "    # make the model more robust\n",
        "    data_augmentation = tf.keras.Sequential(\n",
        "      [\n",
        "        tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n",
        "                                                    input_shape=(IMG_HEIGHT, \n",
        "                                                                  IMG_WIDTH,\n",
        "                                                                  3)),\n",
        "        tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "        tf.keras.layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "      ]\n",
        "    )\n",
        "\n",
        "    # decrease the rate of change towards the end\n",
        "    lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
        "        LEARNING_RATE,\n",
        "        decay_steps=STEPS_PER_EPOCH*1000,\n",
        "        decay_rate=1,\n",
        "        staircase=False)\n",
        "    \n",
        "    # Create the base model from the pre-trained model MobileNet V2\n",
        "    IMG_SHAPE = IMG_SIZE + (3,)\n",
        "    base_model.trainable = False\n",
        "    # bias\n",
        "    #model with several layers\n",
        "    model = tf.keras.models.Sequential([\n",
        "        data_augmentation,                                \n",
        "        # add the convolution layer -> extract feature such as strong colour difference\n",
        "        #-> lernt Kanten\n",
        "        base_model,\n",
        "        # extract information\n",
        "        tf.keras.layers.GlobalAveragePooling2D(),\n",
        "        # add a dropout\n",
        "        tf.keras.layers.Dropout(DROPOUT),\n",
        "        # linear classifier as we want a continues value\n",
        "        tf.keras.layers.Dense(1, activation = \"linear\")\n",
        "    ])\n",
        "    # compile the model\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(lr_schedule),\n",
        "        loss=\"mean_absolute_percentage_error\",\n",
        "        metrics=[\"mean_absolute_percentage_error\"]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYujk9_DX59f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}